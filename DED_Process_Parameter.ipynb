{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/mjjuhasz/Canvasback/blob/master/DED_Process_Parameter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DED Process Parameter Notebook**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=========================================================================\n",
        "Load Specialized Packages (Bayesian Optimization)\n",
        "========================================================================="
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install bayesian-optimization"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bayes_opt import BayesianOptimization"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=========================================================================\n",
        "Load Data and Perform Preprocessing\n",
        "========================================================================="
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset from GitHub Repo\n",
        "Git_Dataset = \"https://raw.githubusercontent.com/mjjuhasz/Canvasback/master/DED_Database.csv\""
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "tf.keras.backend.clear_session() \n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.font_manager\n",
        "\n",
        "from sklearn.metrics import accuracy_score, r2_score, mean_squared_error\n",
        "from sklearn.model_selection import cross_val_score, KFold, train_test_split, StratifiedKFold\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier, IsolationForest\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor, GaussianProcessClassifier \n",
        "from sklearn.gaussian_process.kernels import RBF, WhiteKernel, ConstantKernel\n",
        "from sklearn import svm"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Full_df = pd.read_csv(Git_Dataset)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Graph Histograms of Initial Data**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, (ax1, ax2, ax3, ax4, ax5, ax6) = plt.subplots(1, 6, figsize=(16, 6), tight_layout=True)\n",
        "ax1.hist(Full_df['Power (W)'], density=True, color='tab:orange', edgecolor='k')\n",
        "#ax1.grid()\n",
        "ax1.set_ylabel('Density', weight='bold')\n",
        "ax1.set_xlabel('Power (W)', weight='bold' )\n",
        "ax2.hist(Full_df['Mass Flowrate (g/min)'], density=True, color='tab:orange', edgecolor='k')\n",
        "#ax2.grid()\n",
        "ax2.set_xlabel('Mass Flowrate (g/min)', weight='bold')\n",
        "ax3.hist(Full_df['Traverse Velocity (mm/min)'], density=True, color='tab:orange', edgecolor='k')\n",
        "#ax3.grid()\n",
        "ax3.set_xlabel('Traverse Velocity (mm/min)', weight='bold')\n",
        "ax4.hist(Full_df['Height (mm)'], density=True, color='tab:orange', edgecolor='k')\n",
        "#ax4.grid()\n",
        "ax4.set_xlabel('Height (mm)', weight='bold')\n",
        "ax5.hist(Full_df['Width (mm)'], density=True, color='tab:orange', edgecolor='k')\n",
        "#ax5.grid()\n",
        "ax5.set_xlabel('Width (mm)', weight='bold')\n",
        "ax6.hist(Full_df['Aspect Ratio (H/W)'], density=True, color='tab:orange', edgecolor='k')\n",
        "#ax6.grid()\n",
        "ax6.set_xlabel('Aspect Ratio (H/W)', weight='bold')\n",
        "plt.savefig('Dataset.png', dpi=600)\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prepare Full and PH 13-8 Datasets**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Math = 60 * (Full_df['Power (W)']/Full_df['Traverse Velocity (mm/min)'])\n",
        "LHI = pd.Series(Math, name='Linear Heat Input (J/mm)')\n",
        "df1 = Full_df.join(LHI)\n",
        "PHdf1 = df1[df1['Author/Paper']=='Juhasz'] # Filter on my research\n",
        "FullDS = df1.drop(columns=['Author/Paper', 'Height (mm)', 'Width (mm)', 'Contact Angle (deg)'])\n",
        "FullDS.dropna(subset=['Aspect Ratio (H/W)'], inplace=True)\n",
        "PHDS = PHdf1.drop(columns=['Author/Paper', 'Powder Material', 'Substrate Material', 'Spot Size (mm)', 'Power (W)',\n",
        "                           'Traverse Velocity (mm/min)', 'Contact Angle (deg)'])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Graph Histograms of Preprocessed Data**\n",
        "* Numeric Only - Power Transformed"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FullDSPF = df1.drop(columns=['Author/Paper', 'Powder Material', 'Substrate Material',\n",
        "       'Spot Size (mm)', 'Contact Angle (deg)'])\n",
        "PT = preprocessing.PowerTransformer(method='yeo-johnson', standardize=True, copy=True)\n",
        "P = PT.fit_transform(FullDSPF)\n",
        "PFDF = pd.DataFrame(P, columns=['Power (W)', 'Mass Flowrate (g/min)', 'Traverse Velocity (mm/min)',\n",
        "       'Height (mm)', 'Width (mm)', 'Aspect Ratio (H/W)',\n",
        "       'Linear Heat Input (J/mm)'])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1, 5, figsize=(16, 6), tight_layout=True)\n",
        "ax1.hist(PFDF['Linear Heat Input (J/mm)'], density=True, color='tab:blue', edgecolor='k')\n",
        "ax1.set_ylabel('Density', weight='bold')\n",
        "ax1.set_xlabel('Linear Heat Input (J/mm)', weight='bold' )\n",
        "ax2.hist(PFDF['Mass Flowrate (g/min)'], density=True, color='tab:blue', edgecolor='k')\n",
        "ax2.set_xlabel('Mass Flowrate (g/min)', weight='bold')\n",
        "ax3.hist(PFDF['Height (mm)'], density=True, color='tab:blue', edgecolor='k')\n",
        "ax3.set_xlabel('Height (mm)', weight='bold')\n",
        "ax4.hist(PFDF['Width (mm)'], density=True, color='tab:blue', edgecolor='k')\n",
        "ax4.set_xlabel('Width (mm)', weight='bold')\n",
        "ax5.hist(PFDF['Aspect Ratio (H/W)'], density=True, color='tab:blue', edgecolor='k')\n",
        "ax5.set_xlabel('Aspect Ratio (H/W)', weight='bold')\n",
        "plt.savefig('PTDataset.png', dpi=600)\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sod = StandardScaler()\n",
        "PlotDat = sod.fit_transform(FullDS[['Linear Heat Input (J/mm)','Mass Flowrate (g/min)','Aspect Ratio (H/W)']])\n",
        "fig, (ax1,ax2) = plt.subplots(1, 2, figsize=(10, 5), tight_layout=True)\n",
        "ax1.set_title(\"Scaled Original Data\", weight='bold')\n",
        "ax1.scatter(PlotDat[:,0],PlotDat[:,2], color='gold', edgecolors='k')\n",
        "ax1.scatter(PlotDat[:,1],PlotDat[:,2], color='violet', edgecolors='k')\n",
        "ax1.set_ylabel(\"Aspect Ratio (H/W)\", weight='bold')\n",
        "ax1.set_xlabel(\"Linear Heat Input/Mass Flow Rate , a.u.\", weight='bold')\n",
        "ax1.legend((\"Linear Heat Input\",\"Mass Flowrate\"))\n",
        "ax2.set_title(\"Power-Transformed and Scaled Data\", weight='bold')\n",
        "ax2.scatter(PFDF['Linear Heat Input (J/mm)'],PFDF['Aspect Ratio (H/W)'], color='violet', edgecolors='k')\n",
        "ax2.scatter(PFDF['Mass Flowrate (g/min)'],PFDF['Aspect Ratio (H/W)'], color='gold', edgecolors='k')\n",
        "ax2.set_xlabel(\"Linear Heat Input/Mass Flow Rate , a.u.\", weight='bold')\n",
        "ax2.legend(('Linear Heat Input','Mass Flowrate'))\n",
        "plt.savefig('OrgtoPTDataset.png', dpi=600)\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split Data into X, y and build Pipeline**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle and Split Data\n",
        "FullDS = shuffle(FullDS, random_state=7)\n",
        "X = FullDS.drop(columns='Aspect Ratio (H/W)')\n",
        "y = FullDS['Aspect Ratio (H/W)']"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Impute_Features = ['Spot Size (mm)']\n",
        "Numeric_Features = ['Mass Flowrate (g/min)', 'Linear Heat Input (J/mm)']\n",
        "Categorical_Features = ['Powder Material', 'Substrate Material']\n",
        "impute_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())])\n",
        "power_transformer = preprocessing.PowerTransformer(method='yeo-johnson', standardize=True, copy=True)\n",
        "input_trans=[('impute', impute_transformer , Impute_Features),\n",
        "      ('num', power_transformer, Numeric_Features),\n",
        "      ('cat', OneHotEncoder(), Categorical_Features)]\n",
        "test_trans=[('impute', impute_transformer , Impute_Features),\n",
        "      ('num', 'passthrough', Numeric_Features),\n",
        "      ('cat', OneHotEncoder(), Categorical_Features)]\n",
        "Input_preprocessor = ColumnTransformer(transformers=input_trans)\n",
        "Output_preprocessor = power_transformer\n",
        "Test_preprocessor = ColumnTransformer(transformers=test_trans)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Xrc = Input_preprocessor.fit_transform(X)\n",
        "yr = Output_preprocessor.fit_transform(y.values.reshape(-1,1))\n",
        "Xr_train, Xr_test, yr_train, yr_test = train_test_split(Xrc, yr, test_size=.2)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bins = pd.IntervalIndex.from_tuples([(-.01, .375), (.375, .425), (.425, .475), (.475,.525), (.525,.575), (.575,.625), (.625,2.9)])\n",
        "AR = pd.cut(y, bins=bins)\n",
        "AR1 = AR.to_numpy()\n",
        "LE = preprocessing.LabelEncoder()\n",
        "OHE = preprocessing.OneHotEncoder()\n",
        "yc = LE.fit_transform(AR)\n",
        "ycn = OHE.fit_transform(AR1.reshape(-1,1))\n",
        "Xc_train, Xc_test, yc_train, yc_test = train_test_split(Xrc, yc, test_size=.2)\n",
        "Xcn_train, Xcn_test, ycn_train, ycn_test = train_test_split(Xrc, ycn, test_size=.2)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xx, yy = np.meshgrid(np.linspace(-3, 3, 500), np.linspace(-3, 3, 500))\n",
        "ones = np.ones((xx.ravel().shape[0],1))\n",
        "PM = np.array(['PH13-8']*xx.ravel().shape[0], dtype=object).reshape(-1,1)\n",
        "SM = np.array(['Stainless Steel']*xx.ravel().shape[0], dtype=object).reshape(-1,1)\n",
        "Spot_Size = .75\n",
        "TestDF = pd.DataFrame(np.column_stack(tup=[PM, SM, Spot_Size*ones, ones, yy.ravel(), ones, xx.ravel()]), \n",
        "        columns=['Powder Material', 'Substrate Material','Spot Size (mm)','Power (W)', 'Mass Flowrate (g/min)',\n",
        "                 'Traverse Velocity (mm/min)', 'Linear Heat Input (J/mm)'])\n",
        "Test_preprocessor.fit(X)\n",
        "rcTest = Test_preprocessor.transform(TestDF)    "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=========================================================================\n",
        "Neural Net Hyperparameter Optimization\n",
        "========================================================================="
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bounded region of parameter space\n",
        "pbounds = {'Alpha':(.1,.6),'Epsilon':(.0001,.001),'LNodes':(200,750),'LR':(.00001,.001),\n",
        "           'Momentum':(.05,.2),'NLNodes':(200,1000),'NodeShrink':(.1,1),'NumLayers':(1,3)}\n",
        "optimizer = BayesianOptimization(f=HPc,pbounds=pbounds,\n",
        "    verbose=2, # verbose = 1 prints only when a maximum is observed, verbose = 0 is silent\n",
        "    random_state=21)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer.maximize(init_points=0,n_iter=10)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def HP(Alpha,Epsilon,LNodes,LR,Momentum,NLNodes, NodeShrink, NumLayers):\n",
        "  Ridge = 0.0\n",
        "  Lasso = 0.0\n",
        "  #Momentum = .1\n",
        "  #Epsilon = .005\n",
        "  #Alpha = 1.0\n",
        "  #LR = .001\n",
        "  #NumLayers = 1\n",
        "  #NodeShrink = 1\n",
        "  regRL=tf.keras.regularizers.L1L2(l1=Ridge, l2=Lasso)\n",
        "  # Create Input Layer\n",
        "  inputs = tf.keras.layers.Input(shape=(Xrc.shape[1],))\n",
        "  # Nonlinear Network\n",
        "  NL = layers.Dense(np.round(NLNodes).astype('int'), activation='linear', use_bias=True, kernel_initializer=tf.keras.initializers.GlorotNormal(seed=21), bias_initializer='zeros')(inputs)\n",
        "  # Nonlinear Network Hidden Layers\n",
        "  for n in range(0,np.round(NumLayers).astype('int')):\n",
        "    NL = layers.BatchNormalization(momentum=Momentum, epsilon=Epsilon, center=True, scale=True)(NL)\n",
        "    NL = layers.Dense(np.round(NLNodes*NodeShrink).astype('int'), use_bias=True, kernel_initializer=tf.keras.initializers.GlorotNormal(seed=21), bias_initializer='zeros', kernel_regularizer=regRL)(NL)\n",
        "    NL = layers.ELU(alpha=Alpha)(NL)\n",
        "  # Linear Skip Connection\n",
        "  L = layers.Dense(np.round(LNodes).astype('int'),activation='linear', use_bias=True, kernel_initializer=tf.keras.initializers.GlorotNormal(seed=21), bias_initializer='zeros')(inputs)\n",
        "  # Create Output Layer\n",
        "  x = layers.concatenate([NL, L])\n",
        "  outputs = layers.Dense(1, activation=tf.keras.activations.linear, use_bias=True, kernel_initializer=tf.keras.initializers.GlorotNormal(seed=21), bias_initializer='zeros')(x)\n",
        "  model=tf.keras.Model(inputs=inputs,outputs=outputs)\n",
        "  Opt = tf.keras.optimizers.Adam(learning_rate=LR)\n",
        "  #Loss = tf.keras.losses.MeanSquaredLogarithmicError()\n",
        "  Loss = tf.keras.losses.MeanSquaredError()\n",
        "  model.compile(optimizer=Opt,loss=Loss)\n",
        "  Scores = list()\n",
        "  nfolds = 5\n",
        "  kf = KFold(nfolds, shuffle=True, random_state=21)\n",
        "  fold = 0\n",
        "  for train, test in kf.split(Xrc.toarray()):\n",
        "    fold+=1        \n",
        "    x_train = Xrc[train].toarray()\n",
        "    y_train = yr[train]\n",
        "    x_test = Xrc[test].toarray()\n",
        "    y_test = yr[test]\n",
        "    Report = model.fit(x=x_train,y=y_train,validation_data=[x_test,y_test],batch_size=np.round(Xrc.shape[0]*.01).astype('int'),epochs=50,verbose=0,shuffle=True)\n",
        "    pred = model.predict(x_test)    \n",
        "    score = mean_squared_error(y_test,pred,squared=False)\n",
        "    Scores.append(score)\n",
        "  negmean = -1 * np.mean(Scores)\n",
        "  return negmean"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def HPc(Alpha,Epsilon,LNodes,LR,Momentum,NLNodes, NodeShrink, NumLayers):\n",
        "  Ridge = 0.0\n",
        "  Lasso = 0.0\n",
        "  #Momentum = .1\n",
        "  #Epsilon = .005\n",
        "  #Alpha = 1.0\n",
        "  #LR = .001\n",
        "  #NumLayers = 1\n",
        "  #NodeShrink = 1\n",
        "  #LNodes = 64\n",
        "  #NLNodes = 64\n",
        "  regRL=tf.keras.regularizers.L1L2(l1=Ridge, l2=Lasso)\n",
        "  # Create Input Layer\n",
        "  inputs = tf.keras.layers.Input(shape=(Xrc.shape[1],))\n",
        "  # Nonlinear Network\n",
        "  NL = layers.Dense(np.round(NLNodes).astype('int'), activation='linear', use_bias=True, kernel_initializer=tf.keras.initializers.GlorotNormal(seed=21), bias_initializer='zeros')(inputs)\n",
        "  # Nonlinear Network Hidden Layers\n",
        "  for n in range(0,np.round(NumLayers).astype('int')):\n",
        "    NL = layers.BatchNormalization(momentum=Momentum, epsilon=Epsilon, center=True, scale=True)(NL)\n",
        "    NL = layers.Dense(np.round(NLNodes*NodeShrink).astype('int'), use_bias=True, kernel_initializer=tf.keras.initializers.GlorotNormal(seed=21), bias_initializer='zeros', kernel_regularizer=regRL)(NL)\n",
        "    NL = layers.ELU(alpha=Alpha)(NL)\n",
        "  # Linear Skip Connection\n",
        "  L = layers.Dense(np.round(LNodes).astype('int'),activation='linear', use_bias=True, kernel_initializer=tf.keras.initializers.GlorotNormal(seed=21), bias_initializer='zeros')(inputs)\n",
        "  # Create Output Layer\n",
        "  x = layers.concatenate([NL, L])\n",
        "  outputs = layers.Dense(ycn.shape[1], activation=tf.keras.activations.softmax, use_bias=True, kernel_initializer=tf.keras.initializers.GlorotNormal(seed=21), bias_initializer='zeros')(x)\n",
        "  model=tf.keras.Model(inputs=inputs,outputs=outputs)\n",
        "  Opt = tf.keras.optimizers.Adam(learning_rate=LR)\n",
        "  Loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "  model.compile(optimizer=Opt,loss=Loss)\n",
        "  Scores = list()\n",
        "  nfolds = 5\n",
        "  kf = KFold(nfolds, shuffle=True, random_state=21)\n",
        "  fold = 0\n",
        "  for train, test in kf.split(Xrc.toarray()):\n",
        "    fold+=1        \n",
        "    x_train = Xrc[train].toarray()\n",
        "    y_train = ycn[train].toarray()\n",
        "    x_test = Xrc[test].toarray()\n",
        "    y_test = ycn[test].toarray()\n",
        "    Report = model.fit(x=x_train,y=y_train,validation_data=[x_test,y_test],batch_size=np.round(Xrc.shape[0]*.01).astype('int'),epochs=50,verbose=0,shuffle=True)\n",
        "    pred = model.predict(x_test)\n",
        "    m = tf.keras.metrics.CategoricalCrossentropy()\n",
        "    _ = m.update_state(tf.convert_to_tensor(y_test),pred)\n",
        "    Scores.append(m.result().numpy())\n",
        "  negmean = -1 * np.mean(Scores)\n",
        "  return negmean"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=========================================================================\n",
        "Neural Nets\n",
        "========================================================================="
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_regressor(NLNodes,NumLayers,LNodes):\n",
        "  Ridge = 0.0\n",
        "  Lasso = 0.0\n",
        "  Momentum = .09014\n",
        "  Epsilon = .000577\n",
        "  Alpha = .3088\n",
        "  NodeShrink = .7846\n",
        "  regRL=tf.keras.regularizers.L1L2(l1=Ridge, l2=Lasso)\n",
        "  # Create Input Layer\n",
        "  inputs = tf.keras.layers.Input(shape=(Xrc.shape[1],))\n",
        "  # Nonlinear Network\n",
        "  NL = layers.Dense(NLNodes, activation='linear', use_bias=True, kernel_initializer=tf.keras.initializers.GlorotNormal(seed=21), bias_initializer='zeros')(inputs)\n",
        "  # Nonlinear Network Hidden Layers\n",
        "  for n in range(0,NumLayers):\n",
        "    NL = layers.BatchNormalization(momentum=Momentum, epsilon=Epsilon, center=True, scale=True)(NL)\n",
        "    NL = layers.Dense(np.round(NLNodes*NodeShrink), use_bias=True, kernel_initializer=tf.keras.initializers.GlorotNormal(seed=21), bias_initializer='zeros', kernel_regularizer=regRL)(NL)\n",
        "    NL = layers.ELU(alpha=Alpha)(NL)\n",
        "  # Linear Skip Connection\n",
        "  L = layers.Dense(LNodes,activation='linear', use_bias=True, kernel_initializer=tf.keras.initializers.GlorotNormal(seed=21), bias_initializer='zeros')(inputs)\n",
        "  # Create Output Layer\n",
        "  x = layers.concatenate([NL, L])\n",
        "  outputs = layers.Dense(1, activation='linear', use_bias=True, kernel_initializer=tf.keras.initializers.GlorotNormal(seed=21), bias_initializer='zeros')(x)\n",
        "  #outputs = layers.Dense(1, activation=tf.keras.activations.exponential, use_bias=True, kernel_initializer=tf.keras.initializers.GlorotNormal(seed=21), bias_initializer='zeros')(x)\n",
        "  model=tf.keras.Model(inputs=inputs,outputs=outputs)\n",
        "  return model"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Regressor = build_regressor(210,1,283)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keras.utils.plot_model(Regressor, show_shapes=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Opt = tf.keras.optimizers.Adam(learning_rate=.000871)\n",
        "#Loss = tf.keras.losses.MeanSquaredLogarithmicError()\n",
        "Loss = tf.keras.losses.MeanSquaredError()\n",
        "#def scheduler(epoch):\n",
        "  #if epoch < 10:\n",
        "    #return 0.0001\n",
        "  #if epoch >= 10 and epoch < 25:\n",
        "    #return .0013\n",
        "  #else:\n",
        "    #return 0.0013 * tf.math.exp(0.1 * (25 - epoch))\n",
        "#LRS = tf.keras.callbacks.LearningRateScheduler(scheduler) \n",
        "Monitor = tf.keras.callbacks.EarlyStopping(monitor='val_loss',min_delta=1e-3,patience=100,mode='min',restore_best_weights=True)\n",
        "Regressor.compile(optimizer=Opt,loss=Loss)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "History = Regressor.fit(x=Xrc.toarray(),y=yr,batch_size=np.round(Xrc.shape[0]*.01).astype('int'),epochs=500,callbacks=[Monitor],verbose=1,validation_split=.2,shuffle=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Regressor.save('DEDNNr.h5',save_format='h5')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_classifier(NLNodes,NumLayers,LNodes):\n",
        "  Ridge = 0.0\n",
        "  Lasso = 0.0\n",
        "  Momentum = .1156\n",
        "  Epsilon = .000841\n",
        "  Alpha = .2029\n",
        "  NodeShrink = .6985\n",
        "  regRL=tf.keras.regularizers.L1L2(l1=Ridge, l2=Lasso)\n",
        "  # Create Input Layer\n",
        "  inputs = tf.keras.layers.Input(shape=(Xrc.shape[1],))\n",
        "  # Nonlinear Network\n",
        "  NL = layers.Dense(NLNodes, activation='linear', use_bias=True, kernel_initializer=tf.keras.initializers.GlorotNormal(seed=21), bias_initializer='zeros')(inputs)\n",
        "  # Nonlinear Network Hidden Layers\n",
        "  for n in range(0,NumLayers):\n",
        "    NL = layers.BatchNormalization(momentum=Momentum, epsilon=Epsilon, center=True, scale=True)(NL)\n",
        "    NL = layers.Dense(np.round(NLNodes*NodeShrink), use_bias=True, kernel_initializer=tf.keras.initializers.GlorotNormal(seed=21), bias_initializer='zeros', kernel_regularizer=regRL)(NL)\n",
        "    NL = layers.ELU(alpha=Alpha)(NL)\n",
        "  # Linear Skip Connection\n",
        "  L = layers.Dense(LNodes,activation='linear', use_bias=True, kernel_initializer=tf.keras.initializers.GlorotNormal(seed=21), bias_initializer='zeros')(inputs)\n",
        "  # Create Output Layer\n",
        "  x = layers.concatenate([NL, L])\n",
        "  outputs = layers.Dense(ycn.shape[1], activation=tf.keras.activations.softmax, use_bias=True, kernel_initializer=tf.keras.initializers.GlorotNormal(seed=21), bias_initializer='zeros')(x)\n",
        "  model=tf.keras.Model(inputs=inputs,outputs=outputs)\n",
        "  return model"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Classifier = build_classifier(744,1,358)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keras.utils.plot_model(Classifier, show_shapes=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Optc = tf.keras.optimizers.Adam(learning_rate=.000465)\n",
        "Lossc = tf.keras.losses.CategoricalCrossentropy()\n",
        "#def scheduler(epoch):\n",
        "  #if epoch < 10:\n",
        "    #return 0.0001\n",
        "  #if epoch >= 10 and epoch < 25:\n",
        "    #return .0013\n",
        "  #else:\n",
        "    #return 0.0013 * tf.math.exp(0.1 * (25 - epoch))\n",
        "#LRS = tf.keras.callbacks.LearningRateScheduler(scheduler) \n",
        "Monitor = tf.keras.callbacks.EarlyStopping(monitor='val_loss',min_delta=1e-3,patience=100,mode='min',restore_best_weights=True)\n",
        "Classifier.compile(optimizer=Optc,loss=Lossc)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Historyc = Classifier.fit(x=Xrc.toarray(),y=ycn.toarray(),batch_size=np.round(Xrc.shape[0]*.01).astype('int'),epochs=500,callbacks=[Monitor],verbose=1,validation_split=.2,shuffle=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nnr_score = Regressor.predict(Xr_test.toarray())\n",
        "r2NN = r2_score(yr_test,nnr_score)\n",
        "r2NN"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nnc_score = Classifier.predict(Xcn_test.toarray())\n",
        "r2NNc = accuracy_score(np.argmax(ycn_test, axis=1),np.argmax(nnc_score, axis=1))\n",
        "r2NNc"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nn_y_pred = Regressor.predict(rcTest.toarray())\n",
        "nnr_pred = Regressor.predict(Xrc.toarray())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nnc_y_pred = Classifier.predict(rcTest.toarray())\n",
        "nnc_pred = Classifier.predict(Xrc.toarray())\n",
        "nnc_y_pred = np.argmax(nnc_y_pred, axis=1)\n",
        "nnc_pred = np.argmax(nnc_pred, axis=1)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(10, 8), tight_layout=True)\n",
        "ax1.set_title(\"NN Regression\", weight='bold')\n",
        "CS1 = ax1.contourf(xx, yy, nn_y_pred.reshape(xx.shape), levels=6, cmap=plt.cm.PRGn)\n",
        "ax1.contour(CS1, levels=CS1.levels, colors='k', alpha=.5)\n",
        "fig.colorbar(CS1, ax=ax2)\n",
        "ax1.scatter(Xrc[:,2].toarray(), Xrc[:,1].toarray(), c='gold', s=25, edgecolors='k', alpha=.95)\n",
        "ax1.text(2.75, -1.75, ('%.2f' % r2NN).lstrip('0'), size=12,\n",
        "                bbox=dict(boxstyle='round', alpha=0.8, facecolor='white'), verticalalignment='bottom', horizontalalignment='right')\n",
        "ax1.set_xlim(-3,3)\n",
        "ax1.set_ylim(-2,2)\n",
        "ax1.set_xlabel('Linear Heat Input, Standardized', weight='bold')\n",
        "ax1.set_ylabel('Mass Flowrate, Standardized', weight='bold')\n",
        "ax2.scatter(yr, nnr_pred, c='gold', s=25, edgecolors='k', alpha=.95)\n",
        "ax2.plot([-2,2],[-2,2], '--k')\n",
        "ax2.set_xlim(-2,2)\n",
        "ax2.set_ylim(-2,2)\n",
        "ax2.set_xlabel('Experimental Data', weight='bold')\n",
        "ax2.set_ylabel('Model Predictions', weight='bold')\n",
        "\n",
        "ax3.set_title(\"NN Classification\", weight='bold')\n",
        "CS2 = ax3.contourf(xx, yy, nnc_y_pred.reshape(xx.shape), levels=6, cmap=plt.cm.PRGn)\n",
        "ax3.contour(CS2, levels=CS2.levels, colors='k', alpha=.5)\n",
        "fig.colorbar(CS2, ax=ax4)\n",
        "ax3.scatter(Xrc[:,2].toarray(), Xrc[:,1].toarray(), c='gold', s=25, edgecolors='k', alpha=.95)\n",
        "ax3.text(2.75, -1.75, ('%.2f' % r2NNc).lstrip('0'), size=12,\n",
        "                bbox=dict(boxstyle='round', alpha=0.8, facecolor='white'), verticalalignment='bottom', horizontalalignment='right')\n",
        "ax3.set_xlim(-3,3)\n",
        "ax3.set_ylim(-2,2)\n",
        "ax3.set_xlabel('Linear Heat Input, Standardized', weight='bold')\n",
        "ax3.set_ylabel('Mass Flowrate, Standardized', weight='bold')\n",
        "\n",
        "ax4.hist(nnc_pred, bins=6, alpha=.5, density=True, color='tab:orange', edgecolor='k')\n",
        "ax4.hist(yc, bins=6, alpha=.5, density=True, color='tab:blue', edgecolor='k')\n",
        "ax4.set_xlabel('Class Distribution', weight='bold')\n",
        "ax4.set_ylabel('Density', weight='bold')\n",
        "ax4.legend(('Model Predictions','Experimental data'))\n",
        "plt.savefig('NNresults.png', dpi=600)\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=========================================================================\n",
        "Gaussian Processes\n",
        "========================================================================="
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instantiate a Gaussian Process model"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kernel = (ConstantKernel() * RBF() + WhiteKernel()) + (ConstantKernel() * RBF() + WhiteKernel())\n",
        "gpr = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=50, random_state=21)\n",
        "gpr.fit(Xr_train.toarray(), yr_train)\n",
        "gpr_score = gpr.predict(Xr_test.toarray())\n",
        "r2GPr = r2_score(yr_test, gpr_score)\n",
        "r2GPr"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ckernel = (ConstantKernel() * RBF() + WhiteKernel()) + (ConstantKernel() * RBF() + WhiteKernel())\n",
        "gpc = GaussianProcessClassifier(kernel=ckernel, multi_class='one_vs_one', n_restarts_optimizer=10, max_iter_predict=500, random_state=21)\n",
        "gpc.fit(Xc_train.toarray(),yc_train)\n",
        "gpc_score = gpc.predict(Xc_test.toarray())\n",
        "r2GPc = accuracy_score(yc_test, gpc_score)\n",
        "r2GPc"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpr_y_pred = gpr.predict(rcTest.toarray())\n",
        "gpr_score = gpr.predict(Xrc.toarray())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpc_y_pred = gpc.predict(rcTest.toarray())\n",
        "gpc_score = gpc.predict(Xrc.toarray())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(10, 8), tight_layout=True)\n",
        "ax1.set_title(\"GP Regression\", weight='bold')\n",
        "CS1 = ax1.contourf(xx, yy, gpr_y_pred.reshape(xx.shape), levels=6, cmap=plt.cm.PRGn)\n",
        "ax1.contour(CS1, levels=CS1.levels, colors='k', alpha=.5)\n",
        "fig.colorbar(CS1, ax=ax2)\n",
        "ax1.scatter(Xrc[:,2].toarray(), Xrc[:,1].toarray(), c='gold', s=25, edgecolors='k', alpha=.95)\n",
        "ax1.text(2.75, -1.75, ('%.2f' % r2GPr).lstrip('0'), size=12,\n",
        "                bbox=dict(boxstyle='round', alpha=0.8, facecolor='white'), verticalalignment='bottom', horizontalalignment='right')\n",
        "ax1.set_xlim(-3,3)\n",
        "ax1.set_ylim(-2,2)\n",
        "ax1.set_xlabel('Linear Heat Input, Standardized', weight='bold')\n",
        "ax1.set_ylabel('Mass Flowrate, Standardized', weight='bold')\n",
        "ax2.scatter(yr, gpr_score, c='gold', s=25, edgecolors='k', alpha=.95)\n",
        "ax2.plot([-2,2],[-2,2], '--k')\n",
        "ax2.set_xlim(-2,2)\n",
        "ax2.set_ylim(-2,2)\n",
        "ax2.set_xlabel('Experimental Data', weight='bold')\n",
        "ax2.set_ylabel('Model Predictions', weight='bold')\n",
        "\n",
        "ax3.set_title(\"GP Classification\", weight='bold')\n",
        "CS2 = ax3.contourf(xx, yy, gpc_y_pred.reshape(xx.shape), levels=6, cmap=plt.cm.PRGn)\n",
        "ax3.contour(CS2, levels=CS2.levels, colors='k', alpha=.5)\n",
        "fig.colorbar(CS2, ax=ax4)\n",
        "ax3.scatter(Xrc[:,2].toarray(), Xrc[:,1].toarray(), c='gold', s=25, edgecolors='k', alpha=.95)\n",
        "ax3.text(2.75, -1.75, ('%.2f' % r2GPc).lstrip('0'), size=12,\n",
        "                bbox=dict(boxstyle='round', alpha=0.8, facecolor='white'), verticalalignment='bottom', horizontalalignment='right')\n",
        "ax3.set_xlim(-3,3)\n",
        "ax3.set_ylim(-2,2)\n",
        "ax3.set_xlabel('Linear Heat Input, Standardized', weight='bold')\n",
        "ax3.set_ylabel('Mass Flowrate, Standardized', weight='bold')\n",
        "\n",
        "ax4.hist(gpc_score, bins=6, alpha=.5, density=True, color='tab:orange', edgecolor='k')\n",
        "ax4.hist(yc, bins=6, alpha=.5, density=True, color='tab:blue', edgecolor='k')\n",
        "ax4.set_xlabel('Class Distribution', weight='bold')\n",
        "ax4.set_ylabel('Density', weight='bold')\n",
        "ax4.legend(('Model Predictions','Experimental data'))\n",
        "plt.savefig('GPresults.png', dpi=600)\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=========================================================================\n",
        "Support Vector Machines\n",
        "========================================================================="
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "SVR = svm.SVR(kernel='rbf',gamma='scale',C=5)\n",
        "SVR.fit(Xr_train.toarray(),yr_train)\n",
        "svr_score = SVR.predict(Xr_test.toarray())\n",
        "r2SVR = r2_score(yr_test,svr_score)\n",
        "r2SVR"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SVR_y_pred = SVR.predict(rcTest.toarray())\n",
        "svr_score = SVR.predict(Xrc.toarray())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SVMC = svm.SVC(kernel='rbf',gamma='scale',C=12, random_state=21)\n",
        "SVMC.fit(Xc_train.toarray(),yc_train)\n",
        "svmc_score = SVMC.predict(Xc_test.toarray())\n",
        "r2SVMC = accuracy_score(yc_test,svmc_score)\n",
        "r2SVMC"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SVC_y_pred = SVMC.predict(rcTest.toarray())\n",
        "svmc_score = SVMC.predict(Xrc.toarray())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(10, 8), tight_layout=True)\n",
        "ax1.set_title(\"SVM Regression\", weight='bold')\n",
        "CS1 = ax1.contourf(xx, yy, SVR_y_pred.reshape(xx.shape), levels=6, cmap=plt.cm.PRGn)\n",
        "ax1.contour(CS1, levels=CS1.levels, colors='k', alpha=.5)\n",
        "fig.colorbar(CS1, ax=ax2)\n",
        "ax1.scatter(Xrc[:,2].toarray(), Xrc[:,1].toarray(), c='gold', s=25, edgecolors='k', alpha=.95)\n",
        "ax1.text(2.75, -1.75, ('%.2f' % r2SVR).lstrip('0'), size=12,\n",
        "                bbox=dict(boxstyle='round', alpha=0.8, facecolor='white'), verticalalignment='bottom', horizontalalignment='right')\n",
        "ax1.set_xlim(-3,3)\n",
        "ax1.set_ylim(-2,2)\n",
        "ax1.set_xlabel('Linear Heat Input, Standardized', weight='bold')\n",
        "ax1.set_ylabel('Mass Flowrate, Standardized', weight='bold')\n",
        "ax2.scatter(yr, svr_score, c='gold', s=25, edgecolors='k', alpha=.95)\n",
        "ax2.plot([-2,2],[-2,2], '--k')\n",
        "ax2.set_xlim(-2,2)\n",
        "ax2.set_ylim(-2,2)\n",
        "ax2.set_xlabel('Experimental Data', weight='bold')\n",
        "ax2.set_ylabel('Model Predictions', weight='bold')\n",
        "\n",
        "ax3.set_title(\"SVM Classification\", weight='bold')\n",
        "CS2 = ax3.contourf(xx, yy, SVC_y_pred.reshape(xx.shape), levels=6, cmap=plt.cm.PRGn)\n",
        "ax3.contour(CS2, levels=CS2.levels, colors='k', alpha=.5)\n",
        "fig.colorbar(CS2, ax=ax4)\n",
        "ax3.scatter(Xrc[:,2].toarray(), Xrc[:,1].toarray(), c='gold', s=25, edgecolors='k', alpha=.95)\n",
        "ax3.text(2.75, -1.75, ('%.2f' % r2SVMC).lstrip('0'), size=12,\n",
        "                bbox=dict(boxstyle='round', alpha=0.8, facecolor='white'), verticalalignment='bottom', horizontalalignment='right')\n",
        "ax3.set_xlim(-3,3)\n",
        "ax3.set_ylim(-2,2)\n",
        "ax3.set_xlabel('Linear Heat Input, Standardized', weight='bold')\n",
        "ax3.set_ylabel('Mass Flowrate, Standardized', weight='bold')\n",
        "\n",
        "ax4.hist(yc, bins=6, alpha=.5, density=True, color='tab:blue', edgecolor='k')\n",
        "ax4.hist(svmc_score, bins=6, alpha=.5, density=True, color='tab:orange', edgecolor='k')\n",
        "ax4.set_xlabel('Class Distribution', weight='bold')\n",
        "ax4.set_ylabel('Density', weight='bold')\n",
        "ax4.legend(('Experimental data','Model Predictions'))\n",
        "plt.savefig('SVMresults.png', dpi=600)\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=========================================================================\n",
        "Boosted Trees\n",
        "========================================================================="
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rGBT = GradientBoostingRegressor(n_estimators=1000, learning_rate=0.01, max_depth=20, random_state=21, loss='ls')\n",
        "rGBT.fit(Xr_train.toarray(),yr_train)\n",
        "rGBT_score = rGBT.predict(Xr_test.toarray())\n",
        "r2rGBT = r2_score(yr_test, rGBT_score)\n",
        "r2rGBT"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rGBT_y_pred = rGBT.predict(rcTest.toarray())\n",
        "rGBT_score = rGBT.predict(Xrc.toarray())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cGBT = GradientBoostingClassifier(n_estimators=1000, learning_rate=0.01, max_depth=20, random_state=21, loss='deviance')\n",
        "cGBT.fit(Xc_train.toarray(),yc_train)\n",
        "cGBT_score = cGBT.predict(Xc_test.toarray())\n",
        "r2cGBT = accuracy_score(yc_test, cGBT_score)\n",
        "r2cGBT"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cGBT_y_pred = cGBT.predict(rcTest.toarray())\n",
        "cGBT_score = cGBT.predict(Xrc.toarray())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(10, 8), tight_layout=True)\n",
        "ax1.set_title(\"GBT Regression\", weight='bold')\n",
        "CS1 = ax1.contourf(xx, yy, rGBT_y_pred.reshape(xx.shape), levels=6, cmap=plt.cm.PRGn)\n",
        "ax1.contour(CS1, levels=CS1.levels, colors='k', alpha=.5)\n",
        "fig.colorbar(CS1, ax=ax2)\n",
        "ax1.scatter(Xrc[:,2].toarray(), Xrc[:,1].toarray(), c='gold', s=25, edgecolors='k', alpha=.95)\n",
        "ax1.text(2.75, -1.75, ('%.2f' % r2rGBT).lstrip('0'), size=12,\n",
        "                bbox=dict(boxstyle='round', alpha=0.8, facecolor='white'), verticalalignment='bottom', horizontalalignment='right')\n",
        "ax1.set_xlim(-3,3)\n",
        "ax1.set_ylim(-2,2)\n",
        "ax1.set_xlabel('Linear Heat Input, Standardized', weight='bold')\n",
        "ax1.set_ylabel('Mass Flowrate, Standardized', weight='bold')\n",
        "ax2.scatter(yr, rGBT_score, c='gold', s=25, edgecolors='k', alpha=.95)\n",
        "ax2.plot([-2,2],[-2,2], '--k')\n",
        "ax2.set_xlim(-2,2)\n",
        "ax2.set_ylim(-2,2)\n",
        "ax2.set_xlabel('Experimental Data', weight='bold')\n",
        "ax2.set_ylabel('Model Predictions', weight='bold')\n",
        "\n",
        "ax3.set_title(\"GBT Classification\", weight='bold')\n",
        "CS2 = ax3.contourf(xx, yy, cGBT_y_pred.reshape(xx.shape), levels=6, cmap=plt.cm.PRGn)\n",
        "ax3.contour(CS2, levels=CS2.levels, colors='k', alpha=.5)\n",
        "fig.colorbar(CS2, ax=ax4)\n",
        "ax3.scatter(Xrc[:,2].toarray(), Xrc[:,1].toarray(), c='gold', s=25, edgecolors='k', alpha=.95)\n",
        "ax3.text(2.75, -1.75, ('%.2f' % r2cGBT).lstrip('0'), size=12,\n",
        "                bbox=dict(boxstyle='round', alpha=0.8, facecolor='white'), verticalalignment='bottom', horizontalalignment='right')\n",
        "ax3.set_xlim(-3,3)\n",
        "ax3.set_ylim(-2,2)\n",
        "ax3.set_xlabel('Linear Heat Input, Standardized', weight='bold')\n",
        "ax3.set_ylabel('Mass Flowrate, Standardized', weight='bold')\n",
        "\n",
        "ax4.hist(cGBT_score, bins=6, alpha=.5, density=True, color='tab:orange', edgecolor='k')\n",
        "ax4.hist(yc, bins=6, alpha=.5, density=True, color='tab:blue', edgecolor='k')\n",
        "ax4.set_xlabel('Class Distribution', weight='bold')\n",
        "ax4.set_ylabel('Density', weight='bold')\n",
        "ax4.legend(('Model Predictions','Experimental data'))\n",
        "plt.savefig('GBTresults.png', dpi=600)\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=========================================================================\n",
        "Literature Regression and Summary Plot\n",
        "========================================================================="
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Literature Regression with Height as Response"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LRH = Full_df.dropna(subset=['Height (mm)'])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Wu = LRH['Mass Flowrate (g/min)']/LRH['Traverse Velocity (mm/min)']\n",
        "Felde = ((LRH['Power (W)'] * LRH['Mass Flowrate (g/min)'])**(.5))/LRH['Traverse Velocity (mm/min)']\n",
        "ElCh = ((LRH['Power (W)']**(.25)) * (LRH['Mass Flowrate (g/min)']**(.75)))/LRH['Traverse Velocity (mm/min)']\n",
        "Ansari = ((LRH['Power (W)']**2) * LRH['Mass Flowrate (g/min)'])/(LRH['Traverse Velocity (mm/min)']**1.5)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SS = StandardScaler()\n",
        "Wu = SS.fit_transform(Wu.values.reshape(-1,1))\n",
        "Felde = SS.fit_transform(Felde.values.reshape(-1,1))\n",
        "ElCh = SS.fit_transform(ElCh.values.reshape(-1,1))\n",
        "Ansari = SS.fit_transform(Ansari.values.reshape(-1,1))\n",
        "H = SS.fit_transform(LRH['Height (mm)'].values.reshape(-1,1))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r1 = r2_score(H,Wu)\n",
        "r2 = r2_score(H,Felde)\n",
        "r3 = r2_score(H,ElCh)\n",
        "r4 = r2_score(H,Ansari)\n",
        "r1, r2, r3, r4"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(H,Wu, c='blue', s=25, edgecolors='k', alpha=.75)\n",
        "plt.scatter(H,Felde, c='violet', s=25, edgecolors='k', alpha=.75)\n",
        "plt.scatter(H,ElCh, c='red', s=25, edgecolors='k', alpha=.75)\n",
        "plt.scatter(H,Ansari, c='orange', s=25, edgecolors='k', alpha=.75)\n",
        "plt.plot([-2,12],[-2,12], c='k')\n",
        "plt.xlim(-1.25,6.5)\n",
        "plt.ylim(-1.25,6.5)\n",
        "plt.xlabel('Experimental Data', weight='bold')\n",
        "plt.ylabel('Model Predictions', weight='bold')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Literature Regression with Aspect Ratio as Response"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LRAR = Full_df.dropna(subset=['Aspect Ratio (H/W)'])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Ocelik = LRAR['Mass Flowrate (g/min)']/(LRAR['Power (W)'] * LRAR['Traverse Velocity (mm/min)']**(.5))\n",
        "ElCh =  LRAR['Mass Flowrate (g/min)']**(.75)/(LRAR['Power (W)']**(.5) * LRAR['Traverse Velocity (mm/min)']**(1.25))\n",
        "Ansari = ((LRAR['Power (W)']**(.5)) * LRAR['Mass Flowrate (g/min)'])/(LRAR['Traverse Velocity (mm/min)']**(1.166))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SS1 = StandardScaler()\n",
        "Ocelik = SS1.fit_transform(Ocelik.values.reshape(-1,1))\n",
        "ElCh = SS1.fit_transform(ElCh.values.reshape(-1,1))\n",
        "Ansari = SS1.fit_transform(Ansari.values.reshape(-1,1))\n",
        "ARL = SS1.fit_transform(LRAR['Aspect Ratio (H/W)'].values.reshape(-1,1))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r1 = r2_score(ARL,Ocelik)\n",
        "r2 = r2_score(ARL,ElCh)\n",
        "r3 = r2_score(ARL,Ansari)\n",
        "r1, r2, r3"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(ARL,Ocelik, c='blue', s=25, edgecolors='k', alpha=.75)\n",
        "plt.scatter(ARL,ElCh, c='red', s=25, edgecolors='k', alpha=.75)\n",
        "plt.scatter(ARL,Ansari, c='orange', s=25, edgecolors='k', alpha=.75)\n",
        "plt.plot([-2,12],[-2,12], '--k')\n",
        "plt.title('Combined Parameter Regression from Literature', weight='bold')\n",
        "plt.xlim(-1.5,4.5)\n",
        "plt.ylim(-1.25,6.5)\n",
        "plt.xlabel('Experimental Data', weight='bold')\n",
        "plt.ylabel('Model Predictions', weight='bold')\n",
        "plt.legend(('Ideal','Ocelik et al.','El Cheikh et al.', 'Ansari et al.'))\n",
        "plt.savefig('ARLit.png', dpi=600)\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(8.5,11))\n",
        "grid = fig.add_gridspec(5,4)\n",
        "ax1 = fig.add_subplot(grid[0,:])\n",
        "ax1.scatter(ARL,Ocelik, c='blue', s=25, edgecolors='k', alpha=.75)\n",
        "ax1.scatter(ARL,ElCh, c='red', s=25, edgecolors='k', alpha=.75)\n",
        "ax1.scatter(ARL,Ansari, c='orange', s=25, edgecolors='k', alpha=.75)\n",
        "ax1.plot([-2,12],[-2,12], '--k')\n",
        "ax1.set_xlim(-1.5,4.5)\n",
        "ax1.set_ylim(-1.25,6.5)\n",
        "ax1.set_xlabel('Experimental Data', weight='bold', size=8)\n",
        "ax1.set_ylabel('Literature Predictions', weight='bold', size=8)\n",
        "plt.legend(('Ideal','Ocelik et al.','El Cheikh et al.', 'Ansari et al.'), loc='upper right', fontsize=8)\n",
        "ax1.tick_params(axis='both', labelleft=False, labelbottom=False)\n",
        "\n",
        "ax21 = fig.add_subplot(grid[1,0])\n",
        "CS21 = ax21.contourf(xx, yy, nn_y_pred.reshape(xx.shape), levels=6, cmap=plt.cm.PRGn)\n",
        "ax21.contour(CS21, levels=CS21.levels, colors='k', alpha=.5)\n",
        "ax21.scatter(Xrc[:,2].toarray(), Xrc[:,1].toarray(), c='gold', s=15, edgecolors='k', alpha=.95)\n",
        "ax21.text(2.75, -1.75, ('%.2f' % r2NN).lstrip('0'), size=8,\n",
        "                bbox=dict(boxstyle='round', alpha=0.8, facecolor='white'), verticalalignment='bottom', horizontalalignment='right')\n",
        "ax21.set_xlim(-3,3)\n",
        "ax21.set_ylim(-2,2)\n",
        "ax21.set_ylabel('Neural Nets', weight='bold', size=8)\n",
        "ax21.tick_params(axis='both', labelleft=False, labelbottom=False)\n",
        "ax22 = fig.add_subplot(grid[1,1])\n",
        "ax22.scatter(yr, nnr_pred, c='gold', s=15, edgecolors='k', alpha=.95)\n",
        "ax22.plot([-2,2],[-2,2], '--k')\n",
        "ax22.set_xlim(-2,2)\n",
        "ax22.set_ylim(-2,2)\n",
        "ax22.tick_params(axis='both', labelleft=False, labelbottom=False)\n",
        "ax23 = fig.add_subplot(grid[1,2])\n",
        "CS23 = ax23.contourf(xx, yy, nnc_y_pred.reshape(xx.shape), levels=6, cmap=plt.cm.PRGn)\n",
        "ax23.contour(CS23, levels=CS23.levels, colors='k', alpha=.5)\n",
        "ax23.scatter(Xrc[:,2].toarray(), Xrc[:,1].toarray(), c='gold', s=15, edgecolors='k', alpha=.95)\n",
        "ax23.text(2.75, -1.75, ('%.2f' % r2NNc).lstrip('0'), size=8,\n",
        "                bbox=dict(boxstyle='round', alpha=0.8, facecolor='white'), verticalalignment='bottom', horizontalalignment='right')\n",
        "ax23.set_xlim(-3,3)\n",
        "ax23.set_ylim(-2,2)\n",
        "ax23.tick_params(axis='both', labelleft=False, labelbottom=False)\n",
        "ax24 = fig.add_subplot(grid[1,3])\n",
        "ax24.hist(nnc_pred, bins=6, alpha=.5, density=True, color='tab:orange', edgecolor='k')\n",
        "ax24.hist(yc, bins=6, alpha=.5, density=True, color='tab:blue', edgecolor='k')\n",
        "ax24.legend(('Model Predictions','Experimental data'), fontsize=6)\n",
        "ax24.tick_params(axis='both', labelleft=False, labelbottom=False)\n",
        "\n",
        "ax31 = fig.add_subplot(grid[2,0])\n",
        "CS31 = ax31.contourf(xx, yy, gpr_y_pred.reshape(xx.shape), levels=6, cmap=plt.cm.PRGn)\n",
        "ax31.contour(CS31, levels=CS31.levels, colors='k', alpha=.5)\n",
        "ax31.scatter(Xrc[:,2].toarray(), Xrc[:,1].toarray(), c='gold', s=25, edgecolors='k', alpha=.95)\n",
        "ax31.text(2.75, -1.75, ('%.2f' % r2GPr).lstrip('0'), size=8,\n",
        "                bbox=dict(boxstyle='round', alpha=0.8, facecolor='white'), verticalalignment='bottom', horizontalalignment='right')\n",
        "ax31.set_xlim(-3,3)\n",
        "ax31.set_ylim(-2,2)\n",
        "ax31.set_ylabel('Gaussian Processes', weight='bold', size=8)\n",
        "ax31.tick_params(axis='both', labelleft=False, labelbottom=False)\n",
        "ax32 = fig.add_subplot(grid[2,1])\n",
        "ax32.scatter(yr, gpr_score, c='gold', s=15, edgecolors='k', alpha=.95)\n",
        "ax32.plot([-2,2],[-2,2], c='k')\n",
        "ax32.set_xlim(-2,2)\n",
        "ax32.set_ylim(-2,2)\n",
        "ax32.tick_params(axis='both', labelleft=False, labelbottom=False)\n",
        "ax33 = fig.add_subplot(grid[2,2])\n",
        "CS33 = ax33.contourf(xx, yy, gpc_y_pred.reshape(xx.shape), levels=6, cmap=plt.cm.PRGn)\n",
        "ax33.contour(CS33, levels=CS33.levels, colors='k', alpha=.5)\n",
        "ax33.scatter(Xrc[:,2].toarray(), Xrc[:,1].toarray(), c='gold', s=15, edgecolors='k', alpha=.95)\n",
        "ax33.text(2.75, -1.75, ('%.2f' % r2GPc).lstrip('0'), size=8,\n",
        "                bbox=dict(boxstyle='round', alpha=0.8, facecolor='white'), verticalalignment='bottom', horizontalalignment='right')\n",
        "ax33.set_xlim(-3,3)\n",
        "ax33.set_ylim(-2,2)\n",
        "ax33.tick_params(axis='both', labelleft=False, labelbottom=False)\n",
        "ax34 = fig.add_subplot(grid[2,3])\n",
        "ax34.hist(gpc_score, bins=6, alpha=.5, density=True, color='tab:orange', edgecolor='k')\n",
        "ax34.hist(yc, bins=6, alpha=.5, density=True, color='tab:blue', edgecolor='k')\n",
        "ax34.legend(('Model Predictions','Experimental data'), fontsize=6)\n",
        "ax34.tick_params(axis='both', labelleft=False, labelbottom=False)\n",
        "\n",
        "ax41 = fig.add_subplot(grid[3,0])\n",
        "CS41 = ax41.contourf(xx, yy, SVR_y_pred.reshape(xx.shape), levels=6, cmap=plt.cm.PRGn)\n",
        "ax41.contour(CS41, levels=CS41.levels, colors='k', alpha=.5)\n",
        "ax41.scatter(Xrc[:,2].toarray(), Xrc[:,1].toarray(), c='gold', s=15, edgecolors='k', alpha=.95)\n",
        "ax41.text(2.75, -1.75, ('%.2f' % r2SVR).lstrip('0'), size=8,\n",
        "                bbox=dict(boxstyle='round', alpha=0.8, facecolor='white'), verticalalignment='bottom', horizontalalignment='right')\n",
        "ax41.set_xlim(-3,3)\n",
        "ax41.set_ylim(-2,2)\n",
        "ax41.set_ylabel('Support Vector Machines', weight='bold', size=8)\n",
        "ax41.tick_params(axis='both', labelleft=False, labelbottom=False)\n",
        "ax42 = fig.add_subplot(grid[3,1])\n",
        "ax42.scatter(yr, svr_score, c='gold', s=15, edgecolors='k', alpha=.95)\n",
        "ax42.plot([-2,2],[-2,2], c='k')\n",
        "ax42.set_xlim(-2,2)\n",
        "ax42.set_ylim(-2,2)\n",
        "ax42.tick_params(axis='both', labelleft=False, labelbottom=False)\n",
        "ax43 = fig.add_subplot(grid[3,2])\n",
        "CS43 = ax43.contourf(xx, yy, SVC_y_pred.reshape(xx.shape), levels=6, cmap=plt.cm.PRGn)\n",
        "ax43.contour(CS43, levels=CS43.levels, colors='k', alpha=.5)\n",
        "ax43.scatter(Xrc[:,2].toarray(), Xrc[:,1].toarray(), c='gold', s=15, edgecolors='k', alpha=.95)\n",
        "ax43.text(2.75, -1.75, ('%.2f' % r2SVMC).lstrip('0'), size=8,\n",
        "                bbox=dict(boxstyle='round', alpha=0.8, facecolor='white'), verticalalignment='bottom', horizontalalignment='right')\n",
        "ax43.set_xlim(-3,3)\n",
        "ax43.set_ylim(-2,2)\n",
        "ax43.tick_params(axis='both', labelleft=False, labelbottom=False)\n",
        "ax44 = fig.add_subplot(grid[3,3])\n",
        "ax44.hist(yc, bins=6, alpha=.5, density=True, color='tab:blue', edgecolor='k')\n",
        "ax44.hist(svmc_score, bins=6, alpha=.5, density=True, color='tab:orange', edgecolor='k')\n",
        "ax44.legend(('Experimental data','Model Predictions'), fontsize=6)\n",
        "ax44.tick_params(axis='both', labelleft=False, labelbottom=False)\n",
        "\n",
        "ax51 = fig.add_subplot(grid[4,0])\n",
        "CS51 = ax51.contourf(xx, yy, rGBT_y_pred.reshape(xx.shape), levels=6, cmap=plt.cm.PRGn)\n",
        "ax51.contour(CS51, levels=CS51.levels, colors='k', alpha=.5)\n",
        "ax51.scatter(Xrc[:,2].toarray(), Xrc[:,1].toarray(), c='gold', s=15, edgecolors='k', alpha=.95)\n",
        "ax51.text(2.75, -1.75, ('%.2f' % r2rGBT).lstrip('0'), size=8,\n",
        "                bbox=dict(boxstyle='round', alpha=0.8, facecolor='white'), verticalalignment='bottom', horizontalalignment='right')\n",
        "ax51.set_xlim(-3,3)\n",
        "ax51.set_ylim(-2,2)\n",
        "ax51.set_xlabel('Regression', weight='bold', size=8)\n",
        "ax51.set_ylabel(\"Gradient Boosted Trees\", weight='bold', size=8)\n",
        "ax51.tick_params(axis='both', labelleft=False, labelbottom=False)\n",
        "ax52 = fig.add_subplot(grid[4,1])\n",
        "ax52.scatter(yr, rGBT_score, c='gold', s=15, edgecolors='k', alpha=.95)\n",
        "ax52.plot([-2,2],[-2,2], c='k')\n",
        "ax52.set_xlim(-2,2)\n",
        "ax52.set_ylim(-2,2)\n",
        "ax52.set_xlabel('Regression Fit', weight='bold', size=8)\n",
        "ax52.tick_params(axis='both', labelleft=False, labelbottom=False)\n",
        "ax53 = fig.add_subplot(grid[4,2])\n",
        "CS53 = ax53.contourf(xx, yy, cGBT_y_pred.reshape(xx.shape), levels=6, cmap=plt.cm.PRGn)\n",
        "ax53.contour(CS53, levels=CS53.levels, colors='k', alpha=.5)\n",
        "ax53.scatter(Xrc[:,2].toarray(), Xrc[:,1].toarray(), c='gold', s=15, edgecolors='k', alpha=.95)\n",
        "ax53.text(2.75, -1.75, ('%.2f' % r2cGBT).lstrip('0'), size=8,\n",
        "                bbox=dict(boxstyle='round', alpha=0.8, facecolor='white'), verticalalignment='bottom', horizontalalignment='right')\n",
        "ax53.set_xlim(-3,3)\n",
        "ax53.set_ylim(-2,2)\n",
        "ax53.set_xlabel('Classification', weight='bold', size=8)\n",
        "ax53.tick_params(axis='both', labelleft=False, labelbottom=False)\n",
        "ax54 = fig.add_subplot(grid[4,3])\n",
        "ax54.hist(cGBT_score, bins=6, alpha=.5, density=True, color='tab:orange', edgecolor='k')\n",
        "ax54.hist(yc, bins=6, alpha=.5, density=True, color='tab:blue', edgecolor='k')\n",
        "ax54.set_xlabel('Class Distribution', weight='bold', size=8)\n",
        "ax54.legend(('Model Predictions','Experimental data'), fontsize=6)\n",
        "ax54.tick_params(axis='both', labelleft=False, labelbottom=False)\n",
        "plt.savefig('AllresultsCombined.png', dpi=600)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=======================================================\n",
        "Powder and Substrate Combination Dynamics\n",
        "======================================================="
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X['Powder Material'].value_counts(), X['Substrate Material'].value_counts()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#xx, yy = np.meshgrid(np.linspace(-3, 3, 500), np.linspace(-3, 3, 500))\n",
        "#ones = np.ones((xx.ravel().shape[0],1))\n",
        "PM1 = np.array(['PH13-8']*xx.ravel().shape[0], dtype=object).reshape(-1,1)\n",
        "PM2 = np.array(['316L']*xx.ravel().shape[0], dtype=object).reshape(-1,1)\n",
        "PM3 = np.array(['Ti-6Al-4V']*xx.ravel().shape[0], dtype=object).reshape(-1,1)\n",
        "SM1 = np.array(['Steel']*xx.ravel().shape[0], dtype=object).reshape(-1,1)\n",
        "SM2 = np.array(['Inconel 738']*xx.ravel().shape[0], dtype=object).reshape(-1,1)\n",
        "SM3 = np.array(['316L']*xx.ravel().shape[0], dtype=object).reshape(-1,1)\n",
        "SM4 = np.array(['Ti-6Al-4V']*xx.ravel().shape[0], dtype=object).reshape(-1,1)\n",
        "Spot_Size = .75\n",
        "DF21 = pd.DataFrame(np.column_stack(tup=[PM2, SM1, Spot_Size*ones, ones, yy.ravel(), ones, xx.ravel()]), \n",
        "        columns=['Powder Material', 'Substrate Material','Spot Size (mm)','Power (W)', 'Mass Flowrate (g/min)',\n",
        "                 'Traverse Velocity (mm/min)', 'Linear Heat Input (J/mm)'])\n",
        "DF22 = pd.DataFrame(np.column_stack(tup=[PM2, SM2, Spot_Size*ones, ones, yy.ravel(), ones, xx.ravel()]), \n",
        "        columns=['Powder Material', 'Substrate Material','Spot Size (mm)','Power (W)', 'Mass Flowrate (g/min)',\n",
        "                 'Traverse Velocity (mm/min)', 'Linear Heat Input (J/mm)'])\n",
        "DF23 = pd.DataFrame(np.column_stack(tup=[PM2, SM3, Spot_Size*ones, ones, yy.ravel(), ones, xx.ravel()]), \n",
        "        columns=['Powder Material', 'Substrate Material','Spot Size (mm)','Power (W)', 'Mass Flowrate (g/min)',\n",
        "                 'Traverse Velocity (mm/min)', 'Linear Heat Input (J/mm)'])\n",
        "DF24 = pd.DataFrame(np.column_stack(tup=[PM2, SM4, Spot_Size*ones, ones, yy.ravel(), ones, xx.ravel()]), \n",
        "        columns=['Powder Material', 'Substrate Material','Spot Size (mm)','Power (W)', 'Mass Flowrate (g/min)',\n",
        "                 'Traverse Velocity (mm/min)', 'Linear Heat Input (J/mm)'])\n",
        "DF31 = pd.DataFrame(np.column_stack(tup=[PM3, SM1, Spot_Size*ones, ones, yy.ravel(), ones, xx.ravel()]), \n",
        "        columns=['Powder Material', 'Substrate Material','Spot Size (mm)','Power (W)', 'Mass Flowrate (g/min)',\n",
        "                 'Traverse Velocity (mm/min)', 'Linear Heat Input (J/mm)'])\n",
        "DF32 = pd.DataFrame(np.column_stack(tup=[PM3, SM2, Spot_Size*ones, ones, yy.ravel(), ones, xx.ravel()]), \n",
        "        columns=['Powder Material', 'Substrate Material','Spot Size (mm)','Power (W)', 'Mass Flowrate (g/min)',\n",
        "                 'Traverse Velocity (mm/min)', 'Linear Heat Input (J/mm)'])\n",
        "DF33 = pd.DataFrame(np.column_stack(tup=[PM3, SM3, Spot_Size*ones, ones, yy.ravel(), ones, xx.ravel()]), \n",
        "        columns=['Powder Material', 'Substrate Material','Spot Size (mm)','Power (W)', 'Mass Flowrate (g/min)',\n",
        "                 'Traverse Velocity (mm/min)', 'Linear Heat Input (J/mm)'])\n",
        "DF34 = pd.DataFrame(np.column_stack(tup=[PM3, SM4, Spot_Size*ones, ones, yy.ravel(), ones, xx.ravel()]), \n",
        "        columns=['Powder Material', 'Substrate Material','Spot Size (mm)','Power (W)', 'Mass Flowrate (g/min)',\n",
        "                 'Traverse Velocity (mm/min)', 'Linear Heat Input (J/mm)'])\n",
        "#Test_preprocessor.fit(X)\n",
        "PS21 = Test_preprocessor.transform(DF21)\n",
        "PS22 = Test_preprocessor.transform(DF22)\n",
        "PS23 = Test_preprocessor.transform(DF23)\n",
        "PS24 = Test_preprocessor.transform(DF24)\n",
        "PS31 = Test_preprocessor.transform(DF31)\n",
        "PS32 = Test_preprocessor.transform(DF32)\n",
        "PS33 = Test_preprocessor.transform(DF33)\n",
        "PS34 = Test_preprocessor.transform(DF34)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "comb1 = SVR.predict(PS21.toarray())\n",
        "comb2 = SVR.predict(PS22.toarray())\n",
        "comb3 = SVR.predict(PS23.toarray())\n",
        "comb4 = SVR.predict(PS24.toarray())\n",
        "comb5 = SVR.predict(PS31.toarray())\n",
        "comb6 = SVR.predict(PS32.toarray())\n",
        "comb7 = SVR.predict(PS33.toarray())\n",
        "comb8 = SVR.predict(PS34.toarray())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(14,10))\n",
        "grid = fig.add_gridspec(2,4)\n",
        "ax11 = fig.add_subplot(grid[0,0])\n",
        "CS11 = ax11.contourf(xx, yy, comb1.reshape(xx.shape), levels=6, cmap=plt.cm.PRGn)\n",
        "ax11.contour(CS11, levels=CS11.levels, colors='k', alpha=.5)\n",
        "ax11.scatter(Xrc[:,2].toarray(), Xrc[:,1].toarray(), c='gold', s=25, edgecolors='k', alpha=.95)\n",
        "ax11.set_xlim(-3,3)\n",
        "ax11.set_ylim(-2,2)\n",
        "ax11.set_title('Steel', weight='bold', size=12)\n",
        "ax11.set_ylabel('316L', weight='bold', size=12)\n",
        "ax11.tick_params(axis='both', labelleft=False, labelbottom=False)\n",
        "ax12 = fig.add_subplot(grid[0,1])\n",
        "CS12 = ax12.contourf(xx, yy, comb2.reshape(xx.shape), levels=6, cmap=plt.cm.PRGn)\n",
        "ax12.contour(CS12, levels=CS12.levels, colors='k', alpha=.5)\n",
        "ax12.scatter(Xrc[:,2].toarray(), Xrc[:,1].toarray(), c='gold', s=25, edgecolors='k', alpha=.95)\n",
        "ax12.set_xlim(-3,3)\n",
        "ax12.set_ylim(-2,2)\n",
        "ax12.set_title('Inconel 738', weight='bold', size=12)\n",
        "ax12.tick_params(axis='both', labelleft=False, labelbottom=False)\n",
        "ax13 = fig.add_subplot(grid[0,2])\n",
        "CS13 = ax13.contourf(xx, yy, comb3.reshape(xx.shape), levels=6, cmap=plt.cm.PRGn)\n",
        "ax13.contour(CS13, levels=CS13.levels, colors='k', alpha=.5)\n",
        "ax13.scatter(Xrc[:,2].toarray(), Xrc[:,1].toarray(), c='gold', s=25, edgecolors='k', alpha=.95)\n",
        "ax13.set_xlim(-3,3)\n",
        "ax13.set_ylim(-2,2)\n",
        "ax13.set_title('316L', weight='bold', size=12)\n",
        "ax13.tick_params(axis='both', labelleft=False, labelbottom=False)\n",
        "ax14 = fig.add_subplot(grid[0,3])\n",
        "CS14 = ax14.contourf(xx, yy, comb4.reshape(xx.shape), levels=6, cmap=plt.cm.PRGn)\n",
        "ax14.contour(CS14, levels=CS14.levels, colors='k', alpha=.5)\n",
        "ax14.scatter(Xrc[:,2].toarray(), Xrc[:,1].toarray(), c='gold', s=25, edgecolors='k', alpha=.95)\n",
        "ax14.set_xlim(-3,3)\n",
        "ax14.set_ylim(-2,2)\n",
        "ax14.set_title('Ti-6Al-4V', weight='bold', size=12)\n",
        "ax14.tick_params(axis='both', labelleft=False, labelbottom=False)\n",
        "\n",
        "ax21 = fig.add_subplot(grid[1,0])\n",
        "CS21 = ax21.contourf(xx, yy, comb5.reshape(xx.shape), levels=6, cmap=plt.cm.PRGn)\n",
        "ax21.contour(CS21, levels=CS21.levels, colors='k', alpha=.5)\n",
        "ax21.scatter(Xrc[:,2].toarray(), Xrc[:,1].toarray(), c='gold', s=25, edgecolors='k', alpha=.95)\n",
        "ax21.set_xlim(-3,3)\n",
        "ax21.set_ylim(-2,2)\n",
        "ax21.set_ylabel('Ti-6Al-4V', weight='bold', size=12)\n",
        "ax21.tick_params(axis='both', labelleft=False, labelbottom=False)\n",
        "ax22 = fig.add_subplot(grid[1,1])\n",
        "CS22 = ax22.contourf(xx, yy, comb6.reshape(xx.shape), levels=6, cmap=plt.cm.PRGn)\n",
        "ax22.contour(CS22, levels=CS22.levels, colors='k', alpha=.5)\n",
        "ax22.scatter(Xrc[:,2].toarray(), Xrc[:,1].toarray(), c='gold', s=25, edgecolors='k', alpha=.95)\n",
        "ax22.set_xlim(-3,3)\n",
        "ax22.set_ylim(-2,2)\n",
        "ax22.tick_params(axis='both', labelleft=False, labelbottom=False)\n",
        "ax23 = fig.add_subplot(grid[1,2])\n",
        "CS23 = ax23.contourf(xx, yy, comb7.reshape(xx.shape), levels=6, cmap=plt.cm.PRGn)\n",
        "ax23.contour(CS23, levels=CS23.levels, colors='k', alpha=.5)\n",
        "ax23.scatter(Xrc[:,2].toarray(), Xrc[:,1].toarray(), c='gold', s=25, edgecolors='k', alpha=.95)\n",
        "ax23.set_xlim(-3,3)\n",
        "ax23.set_ylim(-2,2)\n",
        "ax23.tick_params(axis='both', labelleft=False, labelbottom=False)\n",
        "ax24 = fig.add_subplot(grid[1,3])\n",
        "CS24 = ax24.contourf(xx, yy, comb8.reshape(xx.shape), levels=6, cmap=plt.cm.PRGn)\n",
        "ax24.contour(CS24, levels=CS24.levels, colors='k', alpha=.5)\n",
        "ax24.scatter(Xrc[:,2].toarray(), Xrc[:,1].toarray(), c='gold', s=25, edgecolors='k', alpha=.95)\n",
        "ax24.set_xlim(-3,3)\n",
        "ax24.set_ylim(-2,2)\n",
        "ax24.tick_params(axis='both', labelleft=False, labelbottom=False)\n",
        "plt.savefig('PowderSubDynamics.png',dpi=600)\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=======================================================\n",
        "Novelty Detection\n",
        "======================================================="
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PosCases = FullDS[(FullDS['Aspect Ratio (H/W)']>=.475) & (FullDS['Aspect Ratio (H/W)']<=.525)]\n",
        "NegCases = FullDS[(FullDS['Aspect Ratio (H/W)']<.475) | (FullDS['Aspect Ratio (H/W)']>.525)]\n",
        "PosCases = PosCases.drop(columns=['Powder Material', 'Substrate Material', 'Spot Size (mm)',\n",
        "                                  'Power (W)', 'Traverse Velocity (mm/min)','Aspect Ratio (H/W)'])\n",
        "NegCases = NegCases.drop(columns=['Powder Material', 'Substrate Material', 'Spot Size (mm)',\n",
        "                                  'Power (W)', 'Traverse Velocity (mm/min)','Aspect Ratio (H/W)'])\n",
        "PC_MMS = MinMaxScaler(feature_range=(-1,1))\n",
        "NC_MMS = MinMaxScaler(feature_range=(-1,1))\n",
        "PC = PC_MMS.fit_transform(PosCases)\n",
        "NC = NC_MMS.fit_transform(NegCases)\n",
        "PC_train, PC_test = train_test_split(PC, test_size=.2)\n",
        "NC_train, NC_test = train_test_split(NC, test_size=.2)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xxgan, yygan = np.meshgrid(np.linspace(-1, 1, 500), np.linspace(-1, 1, 500))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NDetectPos = svm.OneClassSVM(kernel='rbf',gamma='scale',nu=0.1)\n",
        "#NDetectPos = IsolationForest(n_estimators=1000)\n",
        "NDetectPos.fit(PC_train)\n",
        "Pos_y_pred_train = NDetectPos.predict(PC_train)\n",
        "Pos_y_pred_test = NDetectPos.predict(PC_test)\n",
        "Pos_y_pred_outliers = NDetectPos.predict(NC)\n",
        "Pos_n_error_train = Pos_y_pred_train[Pos_y_pred_train == -1].size\n",
        "Pos_n_error_test = Pos_y_pred_test[Pos_y_pred_test == -1].size\n",
        "Pos_n_error_outliers = Pos_y_pred_outliers[Pos_y_pred_outliers == 1].size\n",
        "#ZPos = NDetectPos.decision_function(rcTest.toarray())\n",
        "ZPos = NDetectPos.decision_function(np.c_[xxgan.ravel(), yygan.ravel()])\n",
        "ZPos = ZPos.reshape(xxgan.shape)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title(\"GAN Preconditioner\", weight='bold')\n",
        "plt.contourf(xxgan, yygan, ZPos, levels=np.linspace(ZPos.min(), 0, 10), cmap=plt.cm.PRGn)\n",
        "a = plt.contour(xxgan, yygan, ZPos, levels=[0], linewidths=2, colors='darkred')\n",
        "plt.contourf(xxgan, yygan, ZPos, levels=[0, ZPos.max()], colors='palevioletred')\n",
        "s = 40\n",
        "b1 = plt.scatter(PC_train[:,1], PC_train[:,0], c='white', s=s, edgecolors='k')\n",
        "b2 = plt.scatter(PC_test[:,1], PC_test[:,0], c='blueviolet', s=s, edgecolors='k')\n",
        "c = plt.scatter(NC[:,1], NC[:,0], c='k', marker='x', s=20, edgecolors='k', alpha=.5)\n",
        "plt.axis('tight')\n",
        "#plt.xlim((-1, -.25))\n",
        "#plt.ylim((-1, -.6))\n",
        "plt.legend([a.collections[0], b1, b2, c],\n",
        "           [\"Decision boundary\", \"Training observations\",\n",
        "            \"Test set positive observations\", \"Test set negative observations\"],\n",
        "           loc=\"upper left\",\n",
        "           prop=matplotlib.font_manager.FontProperties(size=11))\n",
        "plt.xlabel(\n",
        "    \"Training errors: %d/%d ; Test set positive case errors: %d/%d ; \"\n",
        "    \"Test set negative case errors: %d/%d\"\n",
        "    % (Pos_n_error_train, PC_train.shape[0], Pos_n_error_test, PC_train.shape[0], Pos_n_error_outliers, NC.shape[0]))\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_generator(Latent_space,NLNodes,NumLayers,LNodes):\n",
        "  Ridge = 0.0\n",
        "  Lasso = 0.0\n",
        "  Momentum = .09014\n",
        "  Epsilon = .000577\n",
        "  Alpha = .3088\n",
        "  NodeShrink = .7846\n",
        "  regRL=tf.keras.regularizers.L1L2(l1=Ridge, l2=Lasso)\n",
        "  # Create Input Layer\n",
        "  inputs = tf.keras.layers.Input(shape=(Latent_space,))\n",
        "  # Nonlinear Network\n",
        "  NL = layers.Dense(NLNodes, activation='linear', use_bias=True, kernel_initializer=tf.keras.initializers.GlorotNormal(seed=21), bias_initializer='zeros')(inputs)\n",
        "  # Nonlinear Network Hidden Layers\n",
        "  for n in range(0,NumLayers):\n",
        "    NL = layers.BatchNormalization(momentum=Momentum, epsilon=Epsilon, center=True, scale=True)(NL)\n",
        "    NL = layers.Dense(np.round(NLNodes*NodeShrink), use_bias=True, kernel_initializer=tf.keras.initializers.GlorotNormal(seed=21), bias_initializer='zeros', kernel_regularizer=regRL)(NL)\n",
        "    NL = layers.ELU(alpha=Alpha)(NL)\n",
        "  # Linear Skip Connection\n",
        "  L = layers.Dense(LNodes,activation='linear', use_bias=True, kernel_initializer=tf.keras.initializers.GlorotNormal(seed=21), bias_initializer='zeros')(inputs)\n",
        "  # Create Output Layer\n",
        "  x = layers.concatenate([NL, L])\n",
        "  outputs = layers.Dense(2, activation='tanh', use_bias=True, kernel_initializer=tf.keras.initializers.GlorotNormal(seed=21), bias_initializer='zeros')(x)\n",
        "  model=tf.keras.Model(inputs=inputs,outputs=outputs)\n",
        "  return model"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Jenny = build_generator(32,210,1,283)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_discriminator(Generator_output,NLNodes,NumLayers,LNodes):\n",
        "  Ridge = 0.0\n",
        "  Lasso = 0.0\n",
        "  Momentum = .1156\n",
        "  Epsilon = .000841\n",
        "  Alpha = .2029\n",
        "  NodeShrink = .6985\n",
        "  regRL=tf.keras.regularizers.L1L2(l1=Ridge, l2=Lasso)\n",
        "  # Create Input Layer\n",
        "  inputs = tf.keras.layers.Input(shape=(Generator_output,))\n",
        "  # Nonlinear Network\n",
        "  NL = layers.Dense(NLNodes, activation='linear', use_bias=True, kernel_initializer=tf.keras.initializers.GlorotNormal(seed=21), bias_initializer='zeros')(inputs)\n",
        "  # Nonlinear Network Hidden Layers\n",
        "  for n in range(0,NumLayers):\n",
        "    NL = layers.BatchNormalization(momentum=Momentum, epsilon=Epsilon, center=True, scale=True)(NL)\n",
        "    NL = layers.Dense(np.round(NLNodes*NodeShrink), use_bias=True, kernel_initializer=tf.keras.initializers.GlorotNormal(seed=21), bias_initializer='zeros', kernel_regularizer=regRL)(NL)\n",
        "    NL = layers.ELU(alpha=Alpha)(NL)\n",
        "  # Linear Skip Connection\n",
        "  L = layers.Dense(LNodes,activation='linear', use_bias=True, kernel_initializer=tf.keras.initializers.GlorotNormal(seed=21), bias_initializer='zeros')(inputs)\n",
        "  # Create Output Layer\n",
        "  x = layers.concatenate([NL, L])\n",
        "  outputs = layers.Dense(1, activation=tf.keras.activations.sigmoid, use_bias=True, kernel_initializer=tf.keras.initializers.GlorotNormal(seed=21), bias_initializer='zeros')(x)\n",
        "  model=tf.keras.Model(inputs=inputs,outputs=outputs)\n",
        "  return model"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Critic = build_discriminator(2,744,1,358)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Pos_bar = NDetectPos.predict(np.c_[xxgan.ravel(), yygan.ravel()])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def HingeRescale(Vector):\n",
        "  New_Vector = np.ones((len(Vector),1))\n",
        "  for n in np.arange(0,len(Vector)):\n",
        "    if Vector[n]==-1:\n",
        "      New_Vector[n]=0\n",
        "  return New_Vector"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "HingeRS = HingeRescale(Pos_bar)\n",
        "Combined_data = np.column_stack((xxgan.ravel(), yygan.ravel(), HingeRS))\n",
        "Combined_bar = Combined_data[Combined_data[:,2]==1]\n",
        "x_bar = Combined_bar[:,:2]\n",
        "x_bar.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GAN(keras.Model):\n",
        "    def __init__(self, discriminator, generator, latent_dim):\n",
        "        super(GAN, self).__init__()\n",
        "        self.discriminator = discriminator\n",
        "        self.generator = generator\n",
        "        self.latent_dim = latent_dim\n",
        "        \n",
        "    def compile(self, d_optimizer, g_optimizer, d_loss_fn, g_loss_fn, scramble):\n",
        "        super(GAN, self).compile()\n",
        "        self.d_optimizer = d_optimizer\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.d_loss_fn = d_loss_fn\n",
        "        self.g_loss_fn = g_loss_fn\n",
        "        self.scramble = scramble\n",
        "\n",
        "    def train_step(self, X):\n",
        "        if isinstance(X, tuple):\n",
        "            X = X[0]\n",
        "        # Sample random points in the latent space\n",
        "        batch_size = tf.shape(X)[0]\n",
        "        noise = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "        # Decode them to fake data\n",
        "        generated_data = self.generator(noise, training=False)\n",
        "\n",
        "        # Combine them with real data\n",
        "        combined_data = tf.concat([X, generated_data], axis=0)\n",
        "\n",
        "        # Assemble labels discriminating real from fake images (Instance Noise)\n",
        "        true_labels = tf.keras.backend.random_binomial(shape=(batch_size,1), p=self.scramble)\n",
        "        fake_labels = tf.keras.backend.random_binomial(shape=(batch_size,1), p=(1-self.scramble))\n",
        "        labels = tf.concat([true_labels, fake_labels], axis=0)\n",
        "\n",
        "        # Assemble labels discriminating real from fake images\n",
        "        #labels = tf.concat([tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0)\n",
        "        \n",
        "        # Add random noise to the labels - important trick!\n",
        "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
        "\n",
        "        # Train the discriminator\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(combined_data, training=True)\n",
        "            d_loss = self.d_loss_fn(labels, predictions)\n",
        "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
        "        self.d_optimizer.apply_gradients(\n",
        "            zip(grads, self.discriminator.trainable_weights))\n",
        "\n",
        "        # Sample random points in the latent space\n",
        "        noise = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "        # Assemble labels that say \"all real images\"\n",
        "        misleading_labels = tf.ones((batch_size, 1))\n",
        "        misleading_labels += 0.05 * tf.random.uniform(tf.shape(misleading_labels))\n",
        "\n",
        "        # Train the generator (note that we should *not* update the weights\n",
        "        # of the discriminator)!\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(self.generator(noise, training=True), training=False)\n",
        "            g_loss = self.g_loss_fn(misleading_labels, predictions)\n",
        "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
        "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
        "        mean_grad = tf.zeros(())\n",
        "        for grad in grads:\n",
        "          mean_grad += tf.reduce_mean(grad)\n",
        "        mean_grad /= len(grads)\n",
        "        return {\"g_loss\": g_loss,\"g_grads\": mean_grad, \"d_loss\": d_loss}"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gan = GAN(discriminator=Critic, generator=Jenny, latent_dim=32)\n",
        "PreMonitor = tf.keras.callbacks.EarlyStopping(monitor='g_grads',min_delta=1e-6,patience=150,mode='min',restore_best_weights=True)\n",
        "Monitor = tf.keras.callbacks.EarlyStopping(monitor='g_grads',min_delta=1e-6,patience=1000,mode='min',restore_best_weights=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gan.compile(\n",
        "    d_optimizer=keras.optimizers.Adam(learning_rate=0.00005),\n",
        "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0005),\n",
        "    d_loss_fn=tf.keras.losses.BinaryCrossentropy(), g_loss_fn=tf.keras.losses.BinaryCrossentropy(), scramble=.5)\n",
        "gan.fit(x_bar, batch_size=32,callbacks=[PreMonitor],epochs=1500,verbose=1,shuffle=True)\n",
        "gan.compile(\n",
        "    d_optimizer=keras.optimizers.Adam(learning_rate=0.00005),\n",
        "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0005),\n",
        "    d_loss_fn=tf.keras.losses.BinaryCrossentropy(), g_loss_fn=tf.keras.losses.BinaryCrossentropy(), scramble=.6)\n",
        "gan.fit(x_bar, batch_size=32,callbacks=[PreMonitor],epochs=1500,verbose=1,shuffle=True)\n",
        "gan.compile(\n",
        "    d_optimizer=keras.optimizers.Adam(learning_rate=0.00005),\n",
        "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0005),\n",
        "    d_loss_fn=tf.keras.losses.BinaryCrossentropy(), g_loss_fn=tf.keras.losses.BinaryCrossentropy(), scramble=.7)\n",
        "gan.fit(x_bar, batch_size=32,callbacks=[PreMonitor],epochs=1500,verbose=1,shuffle=True)\n",
        "gan.compile(\n",
        "    d_optimizer=keras.optimizers.Adam(learning_rate=0.00005),\n",
        "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0005),\n",
        "    d_loss_fn=tf.keras.losses.BinaryCrossentropy(), g_loss_fn=tf.keras.losses.BinaryCrossentropy(), scramble=.8)\n",
        "gan.fit(x_bar, batch_size=32,callbacks=[PreMonitor],epochs=1500,verbose=1,shuffle=True)\n",
        "gan.compile(\n",
        "    d_optimizer=keras.optimizers.Adam(learning_rate=0.00005),\n",
        "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0005),\n",
        "    d_loss_fn=tf.keras.losses.BinaryCrossentropy(), g_loss_fn=tf.keras.losses.BinaryCrossentropy(), scramble=.9)\n",
        "gan.fit(x_bar, batch_size=32,callbacks=[PreMonitor],epochs=1500,verbose=1,shuffle=True)\n",
        "gan.compile(\n",
        "    d_optimizer=keras.optimizers.Adam(learning_rate=0.00005),\n",
        "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0005),\n",
        "    d_loss_fn=tf.keras.losses.BinaryCrossentropy(), g_loss_fn=tf.keras.losses.BinaryCrossentropy(), scramble=1)\n",
        "gan.fit(x_bar, batch_size=32,callbacks=[Monitor],epochs=1500,verbose=1,shuffle=True)\n",
        "gan.compile(\n",
        "    d_optimizer=keras.optimizers.Adam(learning_rate=0.00005),\n",
        "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0005),\n",
        "    d_loss_fn=tf.keras.losses.BinaryCrossentropy(), g_loss_fn=tf.keras.losses.BinaryCrossentropy(), scramble=1)\n",
        "gan.fit(PC, batch_size=2,callbacks=[Monitor],epochs=1500,verbose=1,shuffle=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gen_data = Jenny(np.random.normal(size=[50000,32]), training=False)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Critic = tf.keras.models.load_model('https://raw.githubusercontent.com/mjjuhasz/Canvasback/master/SVMCritic', compile=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Jenny = tf.keras.models.load_model('https://raw.githubusercontent.com/mjjuhasz/Canvasback/master/SVMJenny', compile=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Position = [-1,-.5,0,.5,1]\n",
        "Distribution = ['GAN Data','Preconditioned Data']\n",
        "for i, num in enumerate(Position):\n",
        "  for j, dist in enumerate(Distribution):\n",
        "    if j == 0:\n",
        "      yvalues = gen_data[(gen_data[:,0]>=(num-.05)) & (gen_data[:,0]<=(num+.05))]\n",
        "    else:\n",
        "      yvalues = x_bar[(x_bar[:,0]>=(num-.05)) & (x_bar[:,0]<=(num+.05))]\n",
        "    #yvalues = yvalues.astype(float)\n",
        "    place = np.ones((yvalues.shape[0],1),dtype=int)*num\n",
        "    distro = np.array([Distribution[j]]*yvalues.shape[0], dtype=object).reshape(-1,1)\n",
        "    stack = np.column_stack((place,distro,yvalues))\n",
        "    if (i == 0) and (j == 0):\n",
        "      finalfig = stack\n",
        "    else:\n",
        "      finalfig = np.concatenate((finalfig,stack))\n",
        "finalfigdf = pd.DataFrame(finalfig, columns=['Position','Distribution','X-values','Y-values'])\n",
        "finalfigdf['Position'] = pd.to_numeric(finalfigdf['Position'])\n",
        "finalfigdf['X-values'] = pd.to_numeric(finalfigdf['X-values'])\n",
        "finalfigdf['Y-values'] = pd.to_numeric(finalfigdf['Y-values'])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(12,4),constrained_layout=True)\n",
        "grid = fig.add_gridspec(1,2)\n",
        "ax1 = fig.add_subplot(grid[0,0])\n",
        "#ax1.set_aspect(1/2)\n",
        "ax1.contourf(xxgan, yygan, ZPos, levels=np.linspace(ZPos.min(), 0, 10), cmap=plt.cm.PRGn)\n",
        "ax1.contour(xxgan, yygan, ZPos, levels=[0], linewidths=2, colors='darkred')\n",
        "ax1.contourf(xxgan, yygan, ZPos, levels=[0, ZPos.max()], colors='palevioletred')\n",
        "a = ax1.scatter(gen_data[:,0], gen_data[:,1], c='tab:orange', s=15, alpha=.25)\n",
        "#ax1.contour(xxgan, yygan, DD, levels=[.95], linewidths=2, colors='darkblue')\n",
        "#ax1.contourf(xxgan, yygan, ZPos, levels=[0, ZPos.max()], colors='palevioletred')\n",
        "b = ax1.scatter(PC[:,1], PC[:,0], c='white', s=40, edgecolors='k')\n",
        "c = ax1.scatter(NC[:,1], NC[:,0], c='k', marker='x', s=20, edgecolors='k', alpha=.5)\n",
        "#plt.xlim((-1, -.25))\n",
        "#plt.ylim((-1, -.6))\n",
        "ax2 = fig.add_subplot(grid[0,1])\n",
        "sns.violinplot(x='Position', y='Y-values', hue='Distribution',hue_order=['Preconditioned Data','GAN Data'] ,\n",
        "               data=finalfigdf, split=True, bw='scott',palette='pastel',inner='quartile')\n",
        "plt.xlabel('')\n",
        "plt.ylabel('')\n",
        "#plt.savefig('GANResults.png', dpi=600)\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 0
}